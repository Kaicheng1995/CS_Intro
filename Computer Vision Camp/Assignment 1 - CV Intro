Q1: What problem does the cloud solve when considering real-world computer vision problems?
 
Firstly, taking Python as an example. With Amazon Web Services Lambda, Python’s limitations for scalability can be solved. In that case, a cloud developer can use SNS, SQS, Lambda, and other building-block technologies because the operating system is AWS itself. It greatly contributes to the development of AI applications. Another problem is that, when dealing with computer vision problems, there could be large amounts of image data produced in daily operations. The storage of image data is an essential aspect of the cloud, and we can turn to the power of cloud computing to handle these data flows. Finally, building a model for visual recognition is difficult. Many ready-to-use solutions developed by various companies like Google, Amazon, and IBM are provided as APIs to solve this problem. For example, Amazon Rekognition is a Computer Vision service which can understand what objects and people are in the scene and what is happening.
 
 
Q2: How could Colab notebooks and/or Jupyter Books be used to exchange ideas or build research portfolios?
 
Colab is a hosted Jupyter Notebook and it has the ability to do GPU/TPU based computing. It has three main interfaces to create notebooks, creating new ones with Python2 or Python3, uploading notebooks and opening notebooks in Github or Drive. In that case, it’s pretty easy to download files with .ipynb postfix, then upload them from different third party systems, and finally run in Colab Notebooks,  which makes ideas can be exchanged in this way. Besides, with Github Integration, the research group can browse Colab Notebooks by adding Colab Load URL at the front of Github URL, and even more, browse Github Repository. This will give us the access to every single repository in Github, or just one’s own organization’s Github repositories. Finally, We can not only save notebooks to Github Repo, but also save copy as Gist. By adding the Open in Colab link, it’s a powerful way to share others with your ideas. Since Colab is a compatible environment in Jupyter, almost everything we can do in Jupyter can be done in Colab.
 
 
Q3: What are some key differences between Biological and Machine Vision?
 
Firstly, different principles. Biological Vision is triggered in cerebral cortex, with the consecutive layers of biological neurons being activated by external stimuli, especially the visual input like simple, straight edges. The regions of the visual cortex contain neurons with concentrations of specializations in different biological functions. While Machine Vision is triggered through algorithm architectures, such as Neocognitron, LeNet-5 and AlexNet, although it is developed from the inspiration of Biological Vision, for instance, Kunihiko Fukushima borrowed the “simple” and “complex” cell conception from Hubel and Wiesel’s work.
 
Besides, different accuracy. With the development of Machine Vision algorithms and datasets, machines surpassed human accuracy in 2015 for the first time, and deep learning is more popular than traditional machine learning approach. Since the information provided by the visual input for Machine Vision, like raw images, is usually limited, and sometimes defective, Machine Vision needs more time on the design and tuning of model architectures, and detect the smallest feature that Biological Vision could possibly recognize, in order to get better performance on the result.
 
Finally, different development trend. Although the development of Machine Vision has benefited from the systematic study of Biological Vision in neurophysiology, psychology and cognitive science, the development of its theories and algorithms is relatively independent and does not deliberately simulate Biological Vision, because at present, the mechanism of Biological Vision has not been clarified, and it has little significance for the development of Machine Vision. The later innovation of Machine Vision is more from experience and intuition, instead of the original concept from Biological Vision.